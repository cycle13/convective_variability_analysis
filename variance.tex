% \documentclass[a4paper, 12pt, draft]{article}
\documentclass[a4paper, 12pt]{article}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{tikz}   % For the for loop
\usepackage[top=3cm, bottom=3cm, left=2.5cm, right=2.5cm]{geometry}
\graphicspath{{/home/s/S.Rasp/Dropbox/figures/PhD/variance/}}

\title{Convective variability in real mid-latitude weather}

\begin{document}
\maketitle
	
\section{Introduction}

\subsection{Motivation}
% parameterizations explained and problems of deterministic parameterizations
Physical processes which occur on scales smaller than the grid spacing of a numerical model typically have to be parameterized. One such process is convection, which acts to restore stability in the atmosphere and is also the cause of significant amounts of precipitation. Parameterizations represent the effect of these sub-grid scale processes on the resolved scales. Traditionally, this is done in a deterministic way, where the mean, most likely, sub-grid effect given a certain large-scale forcing is described. If the sampling size of the unresolved features is large enough, the fluctuations about this mean are indeed small and negligible. For example, a grid box of a climate model with several hundreds of kilometers in size contains many convective features, typically 1-10 km in size. Global weather models nowadays, however, have grid spacings on the order of 10 km. Here the sampling size becomes insufficient and the fluctuation about a mean state are significant. Ignoring these fluctuations can lead to systematic biases in the non-linear atmosphere \citep[e.g.][]{Berner2016} and can also lead to an under-representation of extreme events. Furthermore, in an ensemble system, completely deterministic models are severely underdispersive and, therefore, unreliable. 

% Stochastic parameterizations
Stochastic parameterizations aim to solve the problems outlined above. Here, randomness is introduced to represent the variability associated with sub-grid processes. In an \textit{ad hoc} manner this has been done successfully in medium-range weather prediction for almost two decades \citep{Buizza1999, Berner2009a}. These \textit{ad hoc} methods, however, are finely tuned to give the appropriate spread-skill relation, and do not actually represent the variability associated with a certain physical process. A more physical way of constructing a stochastic parameterization is to explicitly include a physical model of the uncertainty in the formulation of the parameterization. To get a full representation of the complete model uncertainty this has to be done for every parameterized process individually. 
% Other approaches
Several approaches to get a physical model of the underlying uncertainty of convection have been tried. \cite{Dorrestijn2015} and \cite{Gottwald2016} used conditional Markov chains to describe the transition of cloud states. \cite{Bengtsson2013} used cellular automata. One attempt do formulate such a physically-based stochastic parameterization for convection based on statistical mechanics is described now. 

% \cite{Dorrestijn2015} and \cite{Gottwald2016} used conditional Markov chains to describe the transition from one cloud-state to another for several micro-nodes in a GCM grid box. The transition probabilities are dependent on some large scale indicator, in their case the large scale vertical velocity, and the exact values are calculated from observations. This approach allows them to calculate a fraction of deep convective clouds for each grid-box, which can then be used to estimate mass flux for use in a convective parameterization. The advantage of using conditional Markov chains is that they inherently have memory. Application in a simple GCM shows improvements in the distribution of precipitation, and some improvements for equatorial waves \citep{Dorrestijn2016}. 

\subsection{The \cite{Craig2006} theory and its application in \cite{Plant2008}} 
% CC06 theory (following Davoudi2010)
The \cite{Craig2006}(CC06) theory aims to quantify the mass flux fluctuations of a cloud field in convective equilibrium. Convective equilibrium implies that the average properties of the convection are determined by the large-scale forcing. In more detail, the average total mass flux $\langle M \rangle$ is a function of the large-scales. Other assumptions are: (a) the mean mass flux per cloud $\langle m \rangle$ does not depend on the large-scale forcing, only the mean number of clouds $\langle N \rangle$ does; (b) non-interacting clouds: Cloud are spatially separated (no clustering) and do not influence each other. (c) Equal a priori probabilities: This statistical equilibrium assumption implies that ``that clouds are equally likely to occur in any location and with any mass flux''. Using these arguments as a basis, a statistical theory is constructed for the distributions of $N$ and $m$:
\begin{equation} \label{eq:N_dist}
 P(N) = \frac{\langle N \rangle^N}{N!}e^{-\langle N \rangle}
\end{equation}
\begin{equation} \label{eq:m_dist}
 P(m) = \frac{1}{\langle m \rangle}e^{-m/\langle m \rangle}
\end{equation}
Combing these, the distribution of the total mass flux $M$ is given by
\begin{equation} \label{eq:M_dist}
 P(M) = \left( \frac{\langle N \rangle}{\langle m \rangle} \right)^{1/2} e^{-\langle N \rangle} M^{-1/2} e^{-M/\langle m \rangle} I_1\left[ 2 \left( \frac{\langle N \rangle}{\langle m \rangle} M \right)^{1/2} \right],
\end{equation}
where $I_1(x)$is the modified Bessel function of order 1. For large (small) values of $\langle N \rangle$ the shape of this function resembles a Gaussian (Poisson) distribution.   
It is also possible to derive an equation for the normalized variance of $M$:
\begin{equation} \label{eq:M_var}
 \mu_2 = \frac{\langle (\delta M)^2 \rangle}{\langle M \rangle^2} = \frac{2}{\langle N \rangle}
\end{equation}
Always note that $\langle M \rangle = \langle N \rangle \langle m \rangle$. Eq. \ref{eq:M_var} can be derived directly from Eq. \ref{eq:M_dist} or from the theory of random sums \cite[][p.70ff]{Taylor1998}:
% theory of random sums
Assume $X=\xi_1 + ... + \xi_N$ where $\xi_k$ and $N$ have the finite moments $E[\xi_k]=\mu$, $Var[\xi_k]=\sigma^2$ and $E[N]=\nu$, $Var[N]=\tau^2$. Then the first and second moment of $X$ are $E[X]=\mu\nu$, $Var[X]=\nu\sigma^2 + \mu^2\tau^2$.

% Numerical experiments in CC06b
The theoretical predictions above were tested against numerical simulations in radiative-convective equilibrium (RCE) by \cite{Cohen2006}. The results of these simulations agreed well with the theory. The error in $\mu_2$ is around 10\%, with $\mu_2 \langle N \rangle \approx 1.6$. Other studies introduced time-varying forcings and looked at the differences in mass flux statistics as described below.

% Plant Craig 2008 basics: What quantities that I want to look at later are important for a stochastic parameterization
In the \cite{Plant2008}(PC08) stochastic parameterization approach, the exponential $m$ distribution (Eq. \ref{eq:m_dist}) is used to create a random population of plumes for each grid-box consistent with a large scale $\langle M \rangle$. From this distribution the large-scale tendencies are then computed as the sum of the cloud model output for each plume. $\langle m \rangle = 2 \times 10^7$kg s$^{-1}$ is assumed to be a constant. This assumption is motivated by RCE simulations \citep[e.g.][]{Cohen2006}. The theoretical prediction for the variance of $M$ (Eq. \ref{eq:M_var}) is not explicitly used in PC08, but comes from the exponential $m$ distribution combined with the random initiation of new clouds. The cloud life time is set to 45 minutes for all clouds. 

The PC08 scheme has been tested in a GCM study with some success, improving the precipitation patterns and equatorial waves \citep{Wang2016}.

\subsection{Deviations from theory in other studies}
Two studies looked at the deviations from the CC06 predictions in their simulations of convection with a time varying forcing: \cite{Davies2008} and \cite{Davoudi2010}. A quick definition of clustering for this text: Clustering describes the increased probability of occurrence of clouds near already existing clouds. So basically a spike in an RDF. 

\subsubsection{\cite{Davies2008}}
She used a model with 1km resolution, a prescribed radiative cooling and time-varying surface fluxes or temperature. The domain size was 64\,km by 64\,km. For the reference RCE simulation she found $\mu_2 \langle N \rangle \approx 1.5$ at 3 km, a deviation of 10\% in $\mu_2$, which is in agreement with CC06. When looking at their time-varying simulations, they see that $\mu_2$ is increased (about 2.2) 1h after convection is first triggered and at around 15UTC. They find that at the triggering time and at 18UTC there is strong clustering at scales from 5--20 km. At the time of maximum convection (12UTC), the RDF is almost uniform and $\mu_2 \approx 0.7$. She argues that the deviation from the predicted variance can be largely explained by clustering (see Fig.~\ref{fig:Davies2008}). 

\begin{figure}[ht]
\noindent \centering
\includegraphics[width=0.49\textwidth]{Davies2008_Fig5_7.png}
\includegraphics[width=0.49\textwidth]{Davies2008_Fig5_8.png}\\
\caption{From \cite{Davies2008}: (left) $\mu_2$ from their 24\,h time-varying forcing simulation at a height of 3\,km (blue). The black line shows the domain total mass flux at that level. (right) The corresponding RDF for the times indicated (left).} \label{fig:Davies2008}
\end{figure}


\subsubsection{\cite{Davoudi2010}}
They used a similar model setup to CC06, but with a diurnal cycle through interactive radiation with fixed SST. In their Fig. 13, they show their values of $\mu_2 \langle N \rangle$ for different heights. They find that for $z <$8 km, this value is less than two. Additionally, in their Fig. 12. they plot histograms of $P(M)$ from their data. They then fit Eq. \ref{eq:M_dist} with $\langle M \rangle$ and $\langle N \rangle$ as free parameters. When they compare these fitted values to the calculated values of $\langle M \rangle$ and $\langle N \rangle$ from their data, they find that $\langle M \rangle$  is similar but the fitted $\langle N \rangle$ is larger than the observed $\langle N \rangle$. They state that ``Therefore, predictions of $\mu_2$ are smaller than the corresponding normalized variance from the data. Figure 13 demonstrates that the variance, as well as skewness, is underestimated by the theory close to the cloud base and for the range of altitudes in $z \in$  [2, 8] km.'' \textit{This statement seems wrong. Shouldn't it be the other way around? I sent them an email.}

They then look at two clustering metrics. First, the radial distribution function (their Fig. 14), where they find strong clustering for 5-10 km. Second, $\alpha = \frac{\sigma_N^2}{\langle N \rangle}$ (their Fig.~14), where they find values of about 110\% at cloud base, which is in agreement with the findings by CC06 and \cite{Davies2008}. 

\begin{figure}[ht]
\noindent \centering
\includegraphics[width=0.49\textwidth]{Davoudi2010_Fig13.jpeg}
\includegraphics[width=0.49\textwidth]{Davoudi2010_Fig15.jpeg}\\
\caption{From \cite{Davoudi2010}: (left) $\mu_2$ averaged over all times for their simulations at different heights. (right) $\langle N \rangle$ and $\sigma_N^2$ are shown for different heights.} \label{fig:Davoudi2010}
\end{figure}

\subsection{Research questions}
The simple theory of CC06 has been shown to predict the convective variability well in highly idealized simulations and has been used as the basis for the PC08 stochastic convection scheme with some success. Other studies have looked at the influence of a time varying forcing and clustering on convective variability, but these studies also used highly idealized setups. So far, there has been no estimate of the convective variability of a ``real'' weather situation. Particularly the mid-latitudes deviate from RCE simulations in many important ways. The goal of this study is to quantitatively investigate the convective variability in ``real'' mid-latitude weather and compare the results to the theoretical predictions of CC06. More specifically, the research question is:

\textbf{RQ1} How does the convective variability of ``real'' mid-latitude weather situations compare to the predictions of CC06?

\textbf{Hypothesis} There will be some deviations from the theoretical predictions similar to what \cite{Cohen2006}, \cite{Davies2008} and \cite{Davoudi2010} found.

If this hypothesis is true, a follow up research questions is:

\textbf{RQ1.1} To what extent can the deviations of the predicted variability be quantitatively explained by deviation from the underlying assumptions about the distributions of $N$ and $m$?

\textbf{Hypothesis} Clustering (a deviation in the distribution of $N$) can explain a large part of the deviations of the predicted variance.

If this latest hypothesis is not true, then the next follow up research question is:

\textbf{RQ1.2} Can other parameters be found to explain the remaining deviations?

\textbf{Hypothesis} \textit{I don't really have one yet.}.

The hope is that by finding factors which impact the convective variability, stochastic parameterizations can be constructed which include a better representation of the real variability of convection. 

\section{Numerical experiments and case studies}

\subsection{General research strategy}
We will use convection-permitting simulations of real weather situations over Germany. A stochastic boundary-layer scheme will be used to create an ensemble where the convection is displaced. We will then use these ensembles to calculate statistics similar to those in CC06 and compare the results to the theoretical prediction. To explain deviations from the theory, we will try to find meaningful measures to characterize the synoptic situation of the case studies and to correlate them with the deviations.  

\subsection{Numerical experiments}
The model used is the COSMO model with 2.8 km horizontal grid spacing $\Delta x$ and operational COSMO-DE settings with one exception, the stochastic boundary-layer scheme which will be described below. The domain size is 357 grid points in either direction with the domain centered at 10E and 50N. For the analysis a 256 by 256 grid point domain (roughly 717km) at the center of the simulation domain is considered. The 50 grid point gap to the boundary ensures that boundary effects are minimal. 

Initial and boundary conditions are taken from the operational COSMO-EU (7km) deterministic forecast with a boundary condition update frequency of 1 h. All runs are started at 00UTC and are run for 24 h. A 20 member ensemble (\textit{another 30 are currently running}) is created by setting a different random number seed in the stochastic boundary-layer scheme for each member. Otherwise, all members are identical, making sure that the large-scale condition are the same and only the convection is shuffled around. The first three hours are excluded from the analysis to allow for spin up of the simulations and perturbations, so that the analysis starts at 03UTC and ends at 24UTC.

\subsubsection{The PSPturb turbulence scheme}
The physically-based stochastic perturbation boundary-layer scheme (PSPturb) is described and tested in \cite{Kober2016}(KC16). A brief outline is given here now. 

The PSPturb scheme is additive:
\begin{equation} \label{eq:PSPturb_additive}
\left( \frac{\partial \Phi}{\partial t} \right)_{\mathrm{total}} = \left( \frac{\partial \Phi}{\partial t} \right)_{\mathrm{parameterized}} + \eta \sigma_{\left( \frac{\partial \Phi}{\partial t} \right)_{\mathrm{parameterized}}}
\end{equation}
These perturbations (last term) are process-specific, so for each parameterized process the perturbations have to be calculated separately. The last term in the equation above contains a random number $\eta = \mathit{N}(0,1)$ and the standard deviation $\sigma$ of the parameterized tendencies. The random number field has a horizontal correlation length of 5$\Delta x$, the effective resolution and is held constant for 10 minutes and then drawn again from scratch. This represents a typical eddy turnover time in the boundary layer. In KC16 the standard deviation term is approximated by
\begin{equation} \label{eq:PSPturb_std}
\sigma_{\left( \frac{\partial \Phi}{\partial t} \right)_{\mathrm{parameterized}}} = \alpha_{\mathrm{const}, \Phi} \frac{\mathit{l_{\infty}}}{5 \Delta x}\frac{1}{dt} \sigma_{\Phi},
\end{equation}
where $\mathit{l_{\infty}} = 150$ m is the mixing length describing the average size of an eddy. The term $\sigma_{\Phi}$ is the sub-grid scale standard deviation. For the turbulence perturbations the considered variables are vertical velocity $w$, potential temperature $\theta$ and humidity $q$. The standard deviations are calculated in the turbulence parameterization (see KC06 for details). The factor $\frac{\mathit{l_{\infty}}}{5 \Delta x} \propto \frac{1}{\sqrt{N_{\mathrm{eddy}}}}$ scales the variability according to number of unresolved eddies similar to Eq. \ref{eq:M_var}. The factor $\frac{1}{dt}$  converts the term into a tendency term dependent on the time step. Finally, a scaling factor $\alpha_{\mathrm{const}, \Phi}$ is included for tuning purposes and should be of order one. It is set to 2 for these experiments. 

\subsection{Case studies}
The case studies are all from a recent, convectively active period over Central Europe in May/June 2016.  
\paragraph{28 May} The synoptic forcing is weak. Over Southern Germany, high values of CAPE build up (around 1000 J/kg). Scattered diurnal convection develops.
\paragraph{29 May} At night, some rain is advected from the South. Generally, the wind come from the South. During day, CAPE is high in Eastern Germany. There are both scattered convective cells and more stratiform regions.
\paragraph{30 May - 5 June} A low pressure system is stationed over Southern Germany causing easterly advection over Northern Germany. This is coupled with diurnal convection.
\paragraph{6 -- 8 June} The synoptic forcing is weaker with scattered convective cells.

\section{Analyses}

\paragraph{Heigh level of analyses}
Since the height above sea level is not constant for our simulations, the questions arises which level to take for domain averages. Height above sea level would not be a good choice since the vertical location of the statistics since the boundary layer depends on the height above ground level, which would also not be a good choice since the tropopause level is largely unaffected by the height above ground level. A logical choice is to use model levels. In the COSMO model the model levels are terrain-following. In the lower troposphere, they are largely parallel to the ground, but at around 10 km, they are largely parallel to sea level. To pick certain levels, we look at a column above the ocean and search for the closes model level to a height above sea level. 

\subsection{Identification of clouds and calculation of cloud statistics}
To identify clouds, first the fields are converted to binary fields by applying a threshold: Vertical velocity $w >$ 1 m s$^{-1}$ plus a positive cloud water content $q_c >$ 0 kg kg$^{-1}$. This criterion was also used by \cite{Cohen2006} and \cite{Davoudi2010}

% Two different fields and thresholds are used for this study: (1) Vertical velocity $w >$ 1 m s$^{-1}$ plus a positive cloud water content $q_c >$ 0 kg kg$^{-1}$. The criterion is denoted by the letter $m$ (for mass flux). This criterion was also used by \cite{Cohen2006} and \cite{Davoudi2010}. (2) Instantaneous precipitation rate $pr >$ 0.001 mm h$^{-1}$. This is a surface variable. This criterion is denoted by the letter $p$. As of now, only criterion (1) is used!

Contiguous areas are then identified as clouds using a 4-point segmentation algorithm so that only pixels which share an edge are considered as contiguous clouds. Additionally, ``overlapping'' clouds are identified with the local maximum method, followed by a watershed algorithm to find the extent of each separated cloud (for an illustrations see Fig.~\ref{fig:Scheufele2014} (left)).

For each identified cloud $k=1,...,N_{\mathrm{cld},i}$ in each ensemble member $i=1,...,N_{\mathrm{ens}}$ a cloud size $\sigma_k$ is determined as
\begin{equation} \label{eq:cld_size}
 \sigma_k = N_{px} \Delta x^2,
\end{equation}
where $N_{\mathrm{px}}$ is the number of pixels for each cloud $k$. Furthermore, the mass flux per cloud $m_k$ is computed for criterion (1) as
\begin{equation} \label{eq:mass_flux_per_cloud}
 m_k = \Delta x^2 \sum_{l}^{N_{\mathrm{px}}} w_l \rho_l,
\end{equation}
where $\rho$ is density.
% For criterion (2), the precipitation rate per cloud $p_k$ is calculated as
% \begin{equation} \label{eq:pr_per_cloud}
%  p_k = \sum_{px} pr,
% \end{equation}
% Statistics of these variables, such as the mean and the distribution are then calculated (see results).

\subsection{Calculation of radial distribution functions}
A radial distribution function (RDF) is calculated at each time for each member separately. To do this, the center of mass for each cloud is identified. For these points a two-dimensional pair correlation is computed, where the step size of the search function is 2$\Delta x$ and the maximum search radius is 30$\Delta x$. The output is normalized, so that a completely randomly distributed field would give an RDF of 1 at all radii. The results are averaged over the ensemble members to give one RDF at each time. A sketch of how the RDF is calculated is given in Fig.~\ref{fig:Scheufele2014} (right).

\begin{figure}[ht]
\noindent \centering
\includegraphics[width=0.49\textwidth]{Scheufele2014_Fig4_18.jpeg}
\includegraphics[width=0.49\textwidth]{Scheufele2014_Fig3_16.jpeg}\\
\caption{From \cite{Scheufele2014}: (left) Schematic of local maximum method with subsequent watershed method for identifying individual clouds. (right) Schematic of annular regions used to compute mean cloud number density as a function of radius.} \label{fig:Scheufele2014}
\end{figure}

% A clustering radius $r_c$ is defined at the point where the RDF drops below 1 (ignoring the first minimum at small radii if present). 

\subsection{Calculation of ensemble means and variances}
For the variance calculations, a coarse-graining is applied to create coarse boxes $j=1,...,N_{\mathrm{box,n}}$ with edge lengths of $n=$ 256, 128, 64, 32, 16, 8 and 4$\Delta x$, where $N_{\mathrm{box,n}}=n^2$. No neighborhoods smaller are considered, since these would be significantly below the effective resolution of the model \citep{Bierdel2012}. Ensemble statistics are then calculated for each box $j$. The sample variance is computed as
\begin{equation} \label{eq:calc_varM}
 \langle (\delta M )^2 \rangle_{j,n} = \frac{1}{N_{\mathrm{ens}}-1} \sum_{i=1}^{N_{\mathrm{ens}}} (M_{i,j,n} - \langle M \rangle_{j,n})^2,
\end{equation}
where the ensemble mean is
\begin{equation} \label{eq:calc_meanM}
 \langle M \rangle_{j,n} = \frac{1}{N_{\mathrm{ens}}} \sum_{i=1}^{N_{\mathrm{ens}}} M_{i,j,n}.
\end{equation}
These calculations are done analogously for $N$. The total mass flux per box per member $M_{i,j,n}$ is given by
\begin{equation} \label{eq:calc_memM}
 M_{i,j,n} = \sum_{k=1}^{N_{\mathrm{cld}\,i,j,n}} m_{k,i,j,n}.
\end{equation}
To deal with clouds at the boundaries of the coarse-fields, the centers of mass for each cloud is first identified. Then the $m_k$ is attributed to that one point in space. Therefore, the coarse box which contains the center of mass also contains the entire cloud, while the other box does not contain any of the cloud. $N_{i,j,n}=N_{\mathrm{cld}\,i,j,n}$ is simply the number of clouds which fall into each box. This follows \cite{Cohen2006}.

To compute statistics for $m$ a different approach is taken. Here the clouds in all members for each box are considered together to calculate the variance and mean. The total number of clouds over all ensemble members is denoted by $N_{\mathrm{cldtot}} = \sum_{i=1}^{N_{\mathrm{ens}}} N_{\mathrm{cld}\,i,j,n}$.
\begin{equation} \label{eq:calc_varm}
 \langle (\delta m )^2 \rangle_{j,n} = \frac{1}{N_{\mathrm{cldtot}}-1} \sum_{k=1}^{N_{\mathrm{cldtot}}} (m_{k,j,n} - \langle m \rangle_{j,n})^2,
\end{equation}
where the mean is
\begin{equation} \label{eq:calc_meanm}
 \langle m \rangle_{j,n} = \frac{1}{N_{\mathrm{cldtot}}} \sum_{k=1}^{N_{\mathrm{cldtot}}} m_{k,j,n}.
\end{equation}


\paragraph{Sampling issues}
Since we are sampling a distribution with a limited number of data points $N_{\mathrm{ens}}$, sampling issues arise when $\langle N \rangle$ becomes small ($\approx \frac{1}{N_{\mathrm{ens}}}$). In particular, if only one member contains a cloud chances are that the real $\langle N \rangle < \frac{1}{N_{\mathrm{ens}}}$ and we therefore overestimate the mean mass flux $\langle M \rangle$. To avoid this issue, a criterion is introduced where at least 5 out of 20 ensemble members must contain at least one cloud. \textit{This threshold is a quick fix and should be determined statistically.}

\subsection{Comparison with prediction}
To compare the obtained values to the theoretical predictions (\textbf{RQ1}), the normalized variance for each coarse box $j$ at each coarsening scale $n$ is calculated as 
\begin{equation} \label{eq:normalized_variance}
 \mu_{2\,j, n} = \frac{\langle (\delta M )^2 \rangle_{j,n}}{\langle M \rangle_{j,n}^2}.
\end{equation}
To get a quantitative comparison of the simulation results and theory, the fraction is calculated as
\begin{equation} \label{eq:normalized_variance_fraction}
 \frac{\mu_{2\,j, n} \langle N \rangle_{j,n} }{2}.
\end{equation}

To get a summary measure of how the normalized variance compares to the predicted value for each scale $n$, the mean $\frac{\mu_{2} \langle N \rangle}{2}$ is calculated:
\begin{equation} \label{eq:mean_nvar_n}
 \overline{\frac{\mu_{2}\langle N \rangle}{2}}_n = \frac{1}{N_{\mathrm{box}\,n}} \sum_{j=1}^{N_{\mathrm{box}\,n}} \frac{\mu_{2\,j,n}\langle N \rangle_{j,n}}{2}.
\end{equation}
According to theory this value should be 1.
Similarly the standard deviation is calculated as
\begin{equation} \label{eq:std_nvar_n}
 \mathrm{std}\left(\frac{\mu_{2}\langle N \rangle}{2}\right)_n = \sqrt{\frac{1}{N_{\mathrm{box}\,n}-1} \sum_{j=1}^{N_{\mathrm{box}\,n}} \left(\frac{\mu_{2\,j, n} \langle N \rangle_{j,n} }{2} - \overline{\frac{\mu_{2}\langle N \rangle}{2}}_n \right)^2}.
\end{equation}
Coarse grid boxes without any clouds (or less that 5 members out of 20, see above) where excluded from these averages and standard deviation calculations. 

To test whether the assumptions which lead to Eq.~\ref{eq:M_var} hold, we start from the theory of random sums (see above), which states:
\begin{equation} \label{eq:derivation_1}
 \langle (\delta M)^2 \rangle = \langle N \rangle \langle (\delta m)^2 \rangle + \langle m \rangle^2 \langle (\delta N)^2 \rangle
\end{equation}
Assuming an exponential distribution for $m$, so that $\langle (\delta m)^2 \rangle = \langle m \rangle^2$, and a Poisson distribution for $N$, so that $\langle (\delta 
N)^2 \rangle = \langle N \rangle$ gives Eq.~\ref{eq:M_var}. If we do not make these assumptions, however, and divide Eq.~\ref{eq:derivation_1} by $\langle N \rangle \langle m \rangle^2$, we get
\begin{equation} \label{eq:derivation_2}
 \mu_{2\,j,n} \langle N \rangle_{j,n} = \frac{\langle (\delta m)^2 \rangle_{j,n}}{\langle m \rangle_{j,n}^2} + \frac{\langle (\delta N)^2 \rangle_{j,n}}{\langle N \rangle_{j,n}},
\end{equation}
where we define 
\begin{equation} \label{eq:alpha}
 \alpha_{j,n} = \frac{\langle (\delta N)^2 \rangle_{j,n}}{\langle N \rangle_{j,n}}
\end{equation}
following the definition of $\alpha$ from \cite{Davoudi2010} and 
\begin{equation} \label{eq:beta}
 \beta_{j,n} = \frac{\langle (\delta m)^2 \rangle_{j,n}}{\langle m \rangle_{j,n}^2}.
\end{equation}
This allows us to define an ``adjusted'' fraction (cf. Eq.~\ref{eq:normalized_variance_fraction}) as
\begin{equation} \label{eq:adjusted_variance_fraction}
 \frac{\mu_{2\,j, n} \langle N \rangle_{j,n} }{\alpha_{j,n} + \beta_{j,n}},
\end{equation}
which should be 1 if the deviations in the distributions of $m$ and $N$ can account for all of the variance deviation. By setting either $\alpha$ or $\beta$ to 1, we can quantify the effect of each of the distributions individually, thereby answering \textbf{RQ1.1}. Additionally, a summary measure for $\alpha$ and $\beta$ for each $n$ is computed as
\begin{equation} \label{eq:mean_alpha}
 \bar{\alpha}_n = \frac{1}{N_{\mathrm{box}\,n}} \sum_{j=1}^{N_{\mathrm{box}\,n}} \frac{\langle (\delta N)^2 \rangle_{j,n}}{\langle N \rangle_{j,n}}
\end{equation}
and
\begin{equation} \label{eq:mean_beta}
  \bar{\beta}_n = \frac{1}{N_{\mathrm{box}\,n}} \sum_{j=1}^{N_{\mathrm{box}\,n}} \frac{\langle (\delta m)^2 \rangle_{j,n}}{\langle m \rangle_{j,n}^2}.
\end{equation}


\subsection{Calculation of the convective adjustment timescale}
The convective timescale was calculated according to \cite{Flack2016}. To produce ensemble mean plots of $\tau_c$ the fields are calculated for each ensemble member individually and then averaged. This leads to some not-smooth regions at the edges. Furthermore, a minimum precipitation threshold of 0.2 mm h$^{-1}$ is used, which leads to the timescale not being calculated for regions only a few small cells. Therefore, not every variance value can be matched with a timescale value. 

\subsection{Composites}
Composites were computed by averaging over the 12 days in the simulation period. For the calculation of means (every overbar) and standard deviations (std), all coarse boxes at scale $n$ for all ensemble members were first combined, and then the means and standard deviations were calculated. This ensures that, since the number of coarse boxes with clouds will differ from case to case, every coarse box is weighted equally. 

\section{Results (and some thoughts)}
Results are going to be shown for one example day (4 June) and for the composite over all 12 days. For now all results are for model level 30 (corresponds to 3000\,m above sea level.)

\subsection{Cloud field statistics}
Fig.~\ref{fig:ex_stamps_w} shows the mean precipitation and the vertical velocity fields for the first three ensemble members for 14UTC on 4 June as an example. All blue regions in the vertical velocity plots are clouds, if there is a positive cloud water content. Fig.~\ref{fig:ex_cloud_stats} shows the distributions of cloud size and $m$ for the identified clouds at that time for the entire domain. Both distributions resemble an exponential distribution relatively well. For $m$ the distribution at that time for that day seems a little broader. 

Fig.~\ref{fig:comp_summary_stats} shows the temporal evolution for the composite of the domain total mass flux, a measure of the total convective activity, the composite ensemble mean cloud size $\overline{\langle \sigma \rangle}$, the composite ensemble mean cloud mass flux $\overline{\langle m \rangle}$, and the mean convective time scale $\tau_c$. There is a strong diurnal cycle with little convective activity before 10UTC, a peak in the domain total mass flux at around 14UTC and a decrease towards the evening hours. Most of the individual cases follow this diurnal cycle well. Only a few have significant convective activity during the night. The mean cloud size and mass flux is relatively constant, with only a small diurnal signal in the composite, but varies significantly between cases. The convective timescale shows a typical diurnal signal with a build up in the morning hours and a peak around midday. The exact time of the maximum differs between cases. In particular, one case reaches much higher values than all others. In general, the values of $\tau_c$ are moderate (around 10\,h), suggesting that the weather situations are, on average, moderately forced. Looking at the spatial distribution of $\tau_c$ (see for an example Fig.~\ref{fig:ex_stamps_var}), it is evident that the field is very inhomogeneous with both large and small values occurring at the same time in different parts of the domain. 

\subsection{Radial distribution functions}
Fig.~\ref{fig:ex_rdf} and \ref{fig:comp_rdf} show the RDF for several time intervals for 4 June and for the composite, respectively. In both figures, there is increased clustering with a maximum at around 25\,km in the morning and evening hours. At around 100\,km the normalized RDF drops below 1. 

\subsection{Example for upscaled ensemble mean and variance fields}
Fig.~\ref{fig:ex_stamps_var} shows an example of how the field is upscaled and how the variance and mean values are computed. 

\subsection{Comparison with prediction}
Fig.~\ref{fig:comp_scatter} shows how the simulated variances $\mu_2$ compare to predictions $2/\langle N \rangle$ (top row left). The top right plot shows the fraction of simulation variance to prediction $\frac{\mu_2 \langle N \rangle}{2}$ (I will also call it the relative variance). The results for the example case and the composite agree very well, which is why we will focus on the composite results. For all $n$ the simulated variance is below the prediction. For large and small $n$, the deviations are larger, while for $n$ around 100\,km, the simulated variance is very close to the prediction. The standard deviation is typically larger for larger $n$, which could be a results of the smaller sample size. 

The temporal evolution of the means is shown in Fig.~\ref{fig:comp_summary_var}. The top left plot shows the diurnal variation of $\frac{\mu_2 \langle N \rangle}{2}$. The diurnal signal is larger for large $n$. After around 17UTC for $n>$44.8\,km the simulations show a variance which is greater than predicted by theory. 

\paragraph{RQ1} These results enable us to answer the primary research question. The simulated variances show significant deviation from the theoretical predictions of CC06. Typically, the predicted variances are larger than the simulated ones. There is a strong diurnal cycle for larger scales with increased variability in the evening. These results are generally in agreement with previous studies of idealized situations. In particular the diurnal signal seen here looks similar to the one in Fig.~\ref{fig:Davies2008} with a strong increase in convective variability in the evening, even though we do not observe an exceeded variance in the morning. Therefore, the first hypothesis can be confirmed. \\ \\

On to the follow-up RQ1.1:

The second row of Fig.~\ref{fig:comp_scatter} shows the correlation between $\frac{\mu_2 \langle N \rangle}{2}$ and the $\alpha$ parameter (left). For all $n$ there seems to be a good correlation between the deviation fro the observed variance and the clustering as measured by this parameter. The same applies for the temporal evolution shown in Fig.~\ref{fig:comp_summary_var} (bottom left). $\alpha$ shows a strong diurnal signal for larger $n$ which resembles the diurnal signal of the relative variance. Around the convective maximum at midday $\alpha$ is smaller than one, indicating a more regular distribution of cells than what would be expected from a Poisson process. 

Accounting for $\alpha$ in the fraction ($\frac{\mu_2 \langle N \rangle}{1+\alpha}$) (Fig.~\ref{fig:comp_scatter}, second row right) decreases the mean for medium $n$, while for large and small $n$ the mean is largely unaffected. The variability of the variance is greatly decreased for the medium and large $n$. This indicates that for the larger $n$, clustering as measured by $\alpha$ can explain a significant portion of the variability. This can also be seen in the adjusted time evolution (Fig.~\ref{fig:comp_summary_var}, second row left). The diurnal variability is greatly reduced. 

The same can be done for $\beta$ instead of $\alpha$. Here the correlation is less clear, particularly for larger $n$ (Fig.~\ref{fig:comp_scatter}, third row left). There is a strong trend for smaller $\beta$ for smaller $n$, which can also be seen in the temporal means (Fig.~\ref{fig:comp_summary_var}, bottom row right). This could represent a sampling issue, where the very limited number of clouds sampled for small $n$ will most likely have a sharper distribution than the exponential distribution assumed by CC06. There is only a small diurnal signal in $\beta$.

Accounting for $\beta$ in the fraction ($\frac{\mu_2 \langle N \rangle}{1+\beta}$) (Fig.~\ref{fig:comp_scatter}, third row right) results in increased mean variance fractions for medium and small $n$. The variability is not changed significantly. In the temporal evolution plot (Fig.~\ref{fig:comp_summary_var}, second row right) a similar trend can be observed. The mean is changed significantly for small and medium $n$, while the diurnal variation is only reduced slightly. These results indicate that the deviations in $\beta$, most likely owing to sampling issues, are to a large part responsible for the reduced relative variance for small $n$.

Accounting for deviation in both $\alpha$ and $\beta$ ($\frac{\mu_2 \langle N \rangle}{\alpha + \beta}$) (Fig.~\ref{fig:comp_scatter}, bottom row right) shows that for small and medium $n$ the agreement with the theoretical prediction is now very good, and the standard deviation is greatly reduced. For large $n$ there is still a significant deviation in the mean value, but the variability of the variance around mean is also reduced. The temporal means (Fig.~\ref{fig:comp_summary_var}, top row right) for small and medium $n$ basically show no diurnal signal any more and are very close to 1. For large $n$ some of the diurnal variability remains with a minimum during the convective maximum and a maximum in the evening. 

\paragraph{RQ1.1} Deviations in the distributions of $N$ and $m$ can indeed explain a large portion of the deviations of the variances. The clustering as measured by $\alpha$ seems to be responsible for a large chunk of the variability of the relative variances around their mean and the diurnal cycle for larger $n$. $\beta$, on the other hand, shows that for smaller $n$ the simulated $m$ distribution tends to be smaller than exponential. Accounting for $\beta$, therefore, explains, to a large part, the mean deviation of the predicted variance for smaller $n$. By accounting for both, $\alpha$ and $\beta$, the adjusted predictions are very close to relative variance for small and medium $n$. For large $n$, there is still a general trend for the predictions to be higher and some of the diurnal signal remains. In summary, these results suggest that for large scales clustering is important, while for small scales the very limited number of sampled clouds leads to differences in the mass flux per cloud distribution. 

\paragraph{Height dependence} All plots above are valid for 3000\,m asl. Figs.~\ref{fig:comp_height_var} (and below) show the dependence of the variance parameters on height, similar to the plots in \cite{Davoudi2010}, for several time intervals. The results resemble their results. $\frac{\mu_2 \langle N \rangle}{2}$ increases with height. At around 8\,km height the predicted variance agrees well with the simulation results during the convective maximum. the height dependence of $\alpha$ is weak, except for the boundary layer region. At later times (18--20UTC) the clustering for $n$ around 100\,km is clearly visible. $\beta$ has a strong height dependence at all times with lower values in the lower troposphere and higher values in the upper troposphere. This indicates that small clouds which make up the bulk of the distribution in the lower troposphere do not reach the upper parts of the troposphere. Looking at the adjusted predictions one can see that $\alpha$ mainly accounts for the bias between different $n$, while $\beta$ accounts for much of the height variability. 

\paragraph{CC06 vs. SPPT: a different view}
Inspired by \cite{Shutts2007}, Fig.~\ref{fig:comp_std_v_mean} shows the correlation of $\langle M \rangle$ with $\langle (\delta M)^2 \rangle$. According to CC06 they should be in a square root dependence, while the SPPT rationale suggests a linear relation. As can be seen, for the data from the simulations here, the CC06 relation fits better. This suggests that, at least for $M$, the SPPT assumption does not hold. SPPT, however, perturbs the output of the parameterizations, which for convection would be the heating rate $Q$. Therefore, it would be interesting to look at the correlation between $M$ and $Q$. 

\subsection{Spatial correlation}
One question to ask is whether there is any correlation in the deviation in $M_i$ of a member. Specifically, what is the spatial auto-correlation of $M_{i}' = (M_i - \langle M \rangle)/\langle M \rangle$. Fig.~\ref{fig:ex_stamps_corr} shows one example of the field for the first member. As can be seen the field shows some signs of correlation but then also jumps from positive to negative values intermittently. An attempt at constructing an auto-correlation function resulted in values around zero for all distances. Therefore, I will put this inquiry on hold, maybe forever! Temporally, there could be some correlation, but I doubt that with the dataset and method I am using I could find something relevant. 

\subsection{Dependence on ensemble members}
\paragraph{$\beta$-dependence on $n$} $\beta$ seems to depend heavily on $n$. This behavior does not change with the number of ensemble members which suggests one of the following: (a) An error in the computation or (b) an underlying statistical or physical reason for this behavior. A sampling issue whereby $N_{\mathrm{cld}}$ is low for small $n$ does not seem to be the reason as a simple iPython test suggests. To test whether (a) is the case, one option would be to feed the algorithm a ``perfect'' field which fulfills all the assumptions, i.e. a random distribution of clouds with an exponential $m$ distribution. Should $\beta$ be one for all $n$ for this perfect field, this would imply that there is indeed a physical reason. Should a similar $n$ dependence be found, this would hint at a computing error or a statistical reason. 

\subsection{Test with hypothetical fields}
To test whether (a) my algorithm does the right thing and (b) where the deviations in $\alpha$ and $\beta$ come from a hierarchy of idealized fields will be considered.

\subsubsection{Ideal point clouds}
The most idealized test consists of fields with point clouds. The total number of clouds for each ensemble member is drawn from a Poisson distribution with a certain mean. Each cloud is then randomly placed in space with a mass flux drawn from an exponential distribution. The grid is the same as used for the real simulations. The results can be seen in Fig.???. $\alpha$ seems to be smaller 1 at around 0.8, while $\beta$ is basically 1 for all scales. This indicates that the computation of $\beta$ is correct and that the deviations seen in the real simulations have a statistical or physical basis.

\subsubsection{Randomly distributed clouds with a size distributions}
This experiment has circular clouds instead of point clouds.

\subsection{Clustered clouds}
This is Julia's model.

\section{My questions}
Here are some of the questions I have regarding what I have done so far.
\begin{enumerate}
 \item Is my methodology bulletproof or are there assumptions which are not clear?
 \item Is the way I am computing $\langle (\delta m )^2 \rangle_{j,n}$ and $\langle m \rangle_{j,n}$ (Eqs.~\ref{eq:calc_varm} and \ref{eq:calc_meanm}) correct? 
 \item Correlation between $n$ and $\beta$: Is this simply a sampling issue? How is this represented in PC08? Is this intrinsically included in the method of randomly drawing cells?
 \item Are there any further diagnostics of this dataset which would be relevant and interesting?
 \item How are $Q$ and $M$ related in a parameterization? Do SPPT and CC06 contradict each other as \cite{Shutts2007} suggest?
\end{enumerate}

\paragraph{Next steps} Provided that what I have so far is not totally wrong, here are some ideas for next steps:
\begin{enumerate}
 \item How can we predict $\alpha$ from the large-scale environment? Has this already been tried? Or is it too difficult?
 \item How could $\alpha$ be included in PC08? Is this ``beyond the scope of this study''?
 \item What are time and length correlation scales? 
\end{enumerate}



\newpage
\bibliographystyle{ametsoc}
{\small
 \bibliography{library}}

\newpage
\section{Figures}
All plots for level 30 (about 3000m above ground, unless noted otherwise)

\subsection{Example case: June 4}
% Prec and W stamps
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{2016060400/m/stamps_w/stamps_w_2016060400_ana-m_wat-True_lev-34_nens-20_time-00140000.png}\\
\caption{(Top left) Ensemble mean precipitation, (remaining plots) vertical velocity field for the first three ensemble members} \label{fig:ex_stamps_w}
\end{figure}

% Cloud statistics
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{2016060400/m/cloud_stats/cloud_stats_2016060400_ana-m_wat-True_lev-30_nens-20_time-00140000.png}\\
\caption{Cloud statistics for one time step (14UTC): (left) Histogram of cloud size (15 bins with width 0.13e8 m$^2$) (right) histogram of $m$ (15 bins with width 0.5e8 kg/s). Red lines show the mean value.} \label{fig:ex_cloud_stats}
\end{figure}

% Summary stats
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/summary_stats/summary_stats_composite_ana-m_wat-True_lev-30_nens-20_tstart-3_tend-24_tinc-60.png}\\
\caption{Time evolution of (top left) the total mass flux integrated over the analysis domain, (top right) the mean cloud size, (bottom left) the mean mass flux per cloud $\langle m \rangle$ and (bottom right) the domain mean convective time scale} \label{fig:comp_summary_stats}
\end{figure}

% RDF
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{2016060400/m/rdf/rdf_2016060400_ana-m_wat-True_lev-30_nens-20_tstart-3_tend-24_tinc-60.png}\\
\caption{Radial distribution function averaged for 3\,h intervals} \label{fig:ex_rdf}
\end{figure}

% RDF
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/rdf/rdf_composite_ana-m_wat-True_lev-30_nens-20_tstart-3_tend-24_tinc-60.png}\\
\caption{As above but for the composite.} \label{fig:comp_rdf}
\end{figure}

% Var stamps
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{2016060400/m/stamps_var/stamps_var_2016060400_ana-m_wat-True_lev-34_nens-20_time-00140000_n-64.png}\\
\caption{For one time (14UTC) and one $n=64$: (Top left) Ensemble mean convective timescale, (top right) $\mu_{2\,j,n}\langle N \rangle_{j,n}$, (bottom left) $\frac{\langle (\delta N)^2 \rangle_{j,n}}{\langle N \rangle_{j,n}}$ and (bottom right) $\frac{\mu_{2\,j,n}\langle N\rangle_{j,n}}{1 + \alpha_{j,n}}$} \label{fig:ex_stamps_var}
\end{figure}

% % Scatter
% \begin{figure}[ht]
% \noindent \centering
% \includegraphics[width=0.8\textwidth]{2016060400/m/scatter/scatter_2016060400_ana-m_wat-True_lev-30_nens-20.png}\\
% \caption{Scatter plots for several variables. Small dots for each $j$, $n$ is denoted by different colors. The large dots represent the mean values for each $n$.} \label{fig:ex_scatter}
% \end{figure}

% Scatter
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=0.8\textwidth]{composite/m/scatter/scatter_composite_ana-m_wat-True_lev-30_nens-20.png}\\
\caption{Scatter plots for several variables. Small dots for each $j$, $n$ is denoted by different colors. The large dots represent the mean values for each $n$.} \label{fig:comp_scatter}
\end{figure}

% % Summary var
% \begin{figure}[ht]
% \noindent \centering
% \includegraphics[width=\textwidth]{2016060400/m/summary_var/summary_var_2016060400_ana-m_wat-True_lev-30_nens-20_tstart-3_tend-24_tinc-60.png}\\
% \caption{Time evolution for the mean of several variables.} \label{fig:ex_summary_var}
% \end{figure}

% Summary var
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/summary_var/summary_var_composite_ana-m_wat-True_lev-30_nens-20_tstart-3_tend-24_tinc-60.png}\\
\caption{Time evolution for the mean of several variables.} \label{fig:comp_summary_var}
\end{figure}

\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/summary_var/summary_var_composite_ana-m_wat-True_lev-30_nens-20_tstart-3_tend-24_tinc-60.png}\\
\caption{As above but with 50 ensemble members.}
\end{figure}

% Height var
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/height_var/height_var_composite_ana-m_wat-True_nens-20_tstart-3_tend-24_tinc-60_tplot-6-9.png}\\
\caption{Height evolution for the mean of several variables for the interval 9UTC--11UTC.} \label{fig:comp_height_var}
\end{figure}
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/height_var/height_var_composite_ana-m_wat-True_nens-20_tstart-3_tend-24_tinc-60_tplot-9-12.png}\\
\caption{Height evolution for the mean of several variables for the interval 12UTC--14UTC.} 
\end{figure}
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/height_var/height_var_composite_ana-m_wat-True_nens-20_tstart-3_tend-24_tinc-60_tplot-12-15.png}\\
\caption{Height evolution for the mean of several variables for the interval 15UTC--17UTC.}
\end{figure}
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/height_var/height_var_composite_ana-m_wat-True_nens-20_tstart-3_tend-24_tinc-60_tplot-15-18.png}\\
\caption{Height evolution for the mean of several variables for the interval 18UTC--20UTC.}
\end{figure}

% Std_v_mean
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{composite/m/std_v_mean/std_v_mean_composite_ana-m_wat-True_lev-30_nens-20.png}\\
\caption{Relation between $\sigma_M$ and $M$. The dashed line indicates a linear relationship, while the dash-dotted line indicates a square root relationship.} \label{fig:comp_std_v_mean}
\end{figure}


% Var stamps
\begin{figure}[ht]
\noindent \centering
\includegraphics[width=\textwidth]{2016060400/m/stamps_var/new_stamps_var_2016060400_ana-m_wat-True_lev-30_nens-20_time-00140000_n-32.png}\\
\caption{For one time (14UTC) and one $n=64$: (Top left) Ensemble mean convective timescale, (top right) } \label{fig:ex_stamps_corr}
\end{figure}

% Loop
% \foreach \x in {2016052800,2016052900,2016053000,2016053100,2016060200,2016060400,2016060500,2016060600,2016060700,2016060800}
% {
% \subsection{\x}
% 
% \clearpage
% }




\end{document}